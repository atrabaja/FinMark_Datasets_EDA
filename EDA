# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Input CSV files
df1 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_customer_demographics.csv")
df2 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_customer_transactions.csv")
df3 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_social_media_interaction.csv")

# Display first few rows of each dataset to verify they are loaded correctly
print(df1.head())
print(df2.head())
print(df3.head())

# Function to analyze DataFrame structure
def analyze_dataframe(df, df_name):
    # Get the number of variables (columns) and observations (rows)
    num_variables = df.shape[1]
    num_observations = df.shape[0]
    
    # Get data types of each variable
    data_types = df.dtypes
    
    # Display initial observations
    initial_info = df.info()
    
    # Summary message for dataset overview
    summary_message = f"The dataset '{df_name}' contains {num_observations} observations and {num_variables} variables. The variables have the following data types: {data_types.value_counts().to_dict()}."
    
    # Return the analyzed results
    return {
        'DataFrame': df_name,
        'Number of Variables': num_variables,
        'Number of Observations': num_observations,
        'Data Types': data_types,
        'Initial Info': initial_info,
        'Summary': summary_message
    }

# Analyze each DataFrame
results_df1 = analyze_dataframe(df1, "Customer Demographics")
results_df2 = analyze_dataframe(df2, "Customer Transactions")
results_df3 = analyze_dataframe(df3, "Social Media Interactions")

# Print results with enhanced summary
for result in [results_df1, results_df2, results_df3]:
    print(f"\n--- {result['DataFrame']} ---")
    print(f"Number of Variables: {result['Number of Variables']}")
    print(f"Number of Observations: {result['Number of Observations']}")
    print("Data Types:")
    print(result['Data Types'])
    print("Initial Observations:")
    print(result['Initial Info'])
    print("\nSummary:")
    print(result['Summary'])

# Function to assess data quality with enhancements
def assess_data_quality(df, df_name):
    print(f"\nAssessing data quality for {df_name}:")
    
    # 1. Identify missing values
    missing_values = df.isnull().sum()
    print("\nMissing Values:")
    print(missing_values[missing_values > 0])  # Display only columns with missing values

    # 2. Count of missing values
    total_missing = missing_values.sum()
    print(f"\nTotal missing values: {total_missing}")

    # 3. Methods to handle missing data based on the project report
    if total_missing > 0:
        print("\nHandling missing data by imputation or removal based on the specific context of the variables.")

    # 4. Basic statistics for numeric variables
    print("\nBasic Statistics (Mean, Median, Min, Max):")
    print(df.describe())

    # 5. Frequency counts for categorical variables
    categorical_cols = df.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        print("\nFrequency Counts for Categorical Variables:")
        for col in categorical_cols:
            print(f"\n{col}:\n{df[col].value_counts()}")
    
    # 6. Identify and handle outliers using IQR method
    numeric_cols = df.select_dtypes(include=['number']).columns
    print("\nIdentifying outliers using IQR method:")
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        print(f"\nOutliers for {col}:\n{outliers}")
        if not outliers.empty:
            print(f"Handling outliers in '{col}' by considering their context within the dataset.")

# Assess each DataFrame for data quality
assess_data_quality(df1, "Customer Demographics")
assess_data_quality(df2, "Customer Transactions")
assess_data_quality(df3, "Social Media Interactions")

# Descriptive statistics for each DataFrame
desc_df1 = df1.describe(include='all')  # Include all data types
desc_df2 = df2.describe(include='all')  # Include all data types
desc_df3 = df3.describe(include='all')  # Include all data types

# Print descriptive statistics
print("\nDescriptive Statistics for DataFrame 1 - Customer Demographics:")
print(desc_df1)

print("\nDescriptive Statistics for DataFrame 2 - Customer Transactions:")
print(desc_df2)

print("\nDescriptive Statistics for DataFrame 3 - Social Media Interactions:")
print(desc_df3)

# Visualization for Customer Demographics
plt.figure(figsize=(10, 6))
sns.histplot(df1['Age'], bins=30, kde=True)  # Adjust 'Age' to a relevant column in the DataFrame
plt.title('Age Distribution of Customers')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Visualization for Customer Transactions
plt.figure(figsize=(10, 6))
sns.boxplot(x='Product Category', y='Amount', data=df2)  # Use the correct column names
plt.title('Transaction Amount by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Transaction Amount')
plt.xticks(rotation=45)
plt.show()

# Visualization for Social Media Interactions
plt.figure(figsize=(10, 6))
sns.countplot(x='Platform', data=df3)  # Adjust 'Platform' to a relevant column in the DataFrame
plt.title('Number of Interactions by Social Media Platform')
plt.xlabel('Social Media Platform')
plt.ylabel('Number of Interactions')
plt.xticks(rotation=45)
plt.show()
