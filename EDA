# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Input CSV files
df1 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_customer_demographics.csv")
df2 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_customer_transactions.csv")
df3 = pd.read_csv("C:\\Users\\Angel Rabaja\\Downloads\\MO-IT125 Homework_ Data Preprocessing of Machine Learning Solution Project Dataset BSIT-H3103 Mondero, GV., Rabaja, A., Vicente, JB. - cleaned_social_media_interaction.csv")

# Function to analyze DataFrame structure
def analyze_dataframe(df, df_name):
    num_variables = df.shape[1]
    num_observations = df.shape[0]
    data_types = df.dtypes
    summary_message = f"The dataset '{df_name}' contains {num_observations} observations and {num_variables} variables. The variables have the following data types: {data_types.value_counts().to_dict()}."
    
    return {
        'DataFrame': df_name,
        'Number of Variables': num_variables,
        'Number of Observations': num_observations,
        'Data Types': data_types,
        'Summary': summary_message
    }

# Function to assess data quality
def assess_data_quality(df, df_name):
    report = []
    
    report.append(f"\nAssessing data quality for {df_name}:")
    
    # Identify missing values
    missing_values = df.isnull().sum()
    missing_summary = missing_values[missing_values > 0]
    report.append(f"\nMissing Values:\n{missing_summary}")
    
    total_missing = missing_values.sum()
    report.append(f"\nTotal missing values: {total_missing}")
    
    # Basic statistics for numeric variables
    report.append("\nBasic Statistics (Mean, Median, Min, Max):")
    report.append(df.describe().to_string())

    # Frequency counts for categorical variables
    categorical_cols = df.select_dtypes(include=['object']).columns
    if len(categorical_cols) > 0:
        report.append("\nFrequency Counts for Categorical Variables:")
        for col in categorical_cols:
            report.append(f"\n{col}:\n{df[col].value_counts().to_string()}")
    
    # Outlier detection using IQR method
    numeric_cols = df.select_dtypes(include=['number']).columns
    report.append("\nIdentifying outliers using IQR method:")
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        if not outliers.empty:
            report.append(f"\nOutliers for {col}:\n{outliers.to_string()}")

    return "\n".join(report)

# Analyze each DataFrame
results_df1 = analyze_dataframe(df1, "Customer Demographics")
results_df2 = analyze_dataframe(df2, "Customer Transactions")
results_df3 = analyze_dataframe(df3, "Social Media Interactions")

# Assign data quality assessment results
data_quality_df1 = assess_data_quality(df1, "Customer Demographics")
data_quality_df2 = assess_data_quality(df2, "Customer Transactions")
data_quality_df3 = assess_data_quality(df3, "Social Media Interactions")

# Save analysis and data quality results to a text file
with open("data_analysis_report.txt", "w") as file:
    # Write the structure analysis results
    for result in [results_df1, results_df2, results_df3]:
        file.write(f"\n--- {result['DataFrame']} ---\n")
        file.write(f"Number of Variables: {result['Number of Variables']}\n")
        file.write(f"Number of Observations: {result['Number of Observations']}\n")
        file.write("Data Types:\n")
        file.write(result['Data Types'].to_string())
        file.write("\nSummary:\n")
        file.write(result['Summary'])
        file.write("\n\n")
    
    # Write the data quality assessment
    file.write("\n--- Data Quality Assessment ---\n")
    file.write(data_quality_df1)
    file.write("\n\n")
    file.write(data_quality_df2)
    file.write("\n\n")
    file.write(data_quality_df3)
    file.write("\n\n")

# Print a message to confirm saving the file
print("Data analysis and data quality results have been saved to 'data_analysis_report.txt'")

# Visualization for Customer Demographics
plt.figure(figsize=(10, 6))
sns.histplot(df1['Age'], bins=10, kde=True)  # Changed bin size to 10
plt.title('Customer Age Distribution')
plt.xlabel('Age Range (Years)')  
plt.ylabel('Number of Customers')  
plt.xticks(range(15, 75, 5))  # Set x-axis ticks every 5 years
plt.savefig("customer_age_distribution.png")  # Save plot as image
plt.show()

# Visualization for Customer Transactions
plt.figure(figsize=(10, 6))
sns.boxplot(x='Product Category', y='Amount', data=df2)  # Use the correct column names
plt.title('Transaction Amount by Product Category')
plt.xlabel('Product Category')
plt.ylabel('Transaction Amount')
plt.xticks(rotation=45)
plt.savefig("transaction_amount_by_product_category.png")  # Save plot as image
plt.show()

# Visualization for Social Media Interactions
plt.figure(figsize=(10, 6))
sns.countplot(x='Platform', data=df3)  # Adjust 'Platform' to a relevant column in the DataFrame
plt.title('Number of Interactions by Social Media Platform')
plt.xlabel('Social Media Platform')
plt.ylabel('Number of Interactions')
plt.xticks(rotation=45)
plt.savefig("social_media_interactions_by_platform.png")  # Save plot as image
plt.show()
